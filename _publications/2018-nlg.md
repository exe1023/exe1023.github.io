---
title: "Natural Language Generation by Hierarchical Decoding with Linguistic Patterns"
collection: publications
permalink: /publication/2018-nlg
excerpt: '
Shang-Yu Su, Kai-Ling Lo, **Yi-Ting Yeh**, and Yun-Nung Chen.
'
date: 2018-06-01
venue: 'The 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)'
paperurl: 'https://arxiv.org/abs/1808.02747'
codeurl: 'https://github.com/MiuLab/HNLG'

---

Shang-Yu Su, Kai-Ling Lo, **Yi-Ting Yeh**, and Yun-Nung Chen.

Full Paper: [arXiv](https://arxiv.org/abs/1808.02747)

Code: [GitHub](https://github.com/MiuLab/HNLG)

Natural language generation (NLG) is a critical  component  in  spoken  dialogue  systems.

Classic NLG can be divided into two phases:

1.  sentence planning: deciding on the overallsentence structure 
2.  surface realization: determining  specific  word  forms  and  flatteningthe sentence structure into a string. 

Many simple NLG models are based on recurrent neural networks (RNN) and sequence-to-sequence(seq2seq) model, which basically contains an encoder-decoder structure; these NLG models generate sentences from scratch by jointly optimizing  sentence  planning  and  surface  realization using a simple cross entropy loss training  criterion.

However,  the  simple  encoder-decoder architecture usually suffers from generating complex and long sentences,  becausethe decoder has to learn all grammar and diction  knowledge.   

This  paper  introduces  a  hierarchical decoding NLG model based on linguistic patterns in different levels, and shows that the proposed method outperforms the traditional one with a smaller model size.   Furthermore, the design of the hierarchical decoding is flexible and easily-extensible in various NLG systems



